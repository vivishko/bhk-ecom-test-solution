#### мысль по реализации №1

1 сервис, глобальная структура вида </br>
{ timestamp: в минутах, countersMap: map[string]int } </br>
структура собирает данные и раз в минуту (проверка текущего timestamp при каждом обновлении каунтера) отправляет их в бд

хранение в бд: _banner_id, minute_timestamp, count_

| плюсы                            | минусы                                 |
| -------------------------------- | -------------------------------------- |
| удобство работы с одним сервисом | потеря данных в случае падения сервиса |
|                                  | частый INSERT в бд                     |

---

#### мысль по реализации №2

проблема: если сервис из №1 упадёт, то потеряются данные за прошлую минуту, собираемые этой структурой

можно попробовать сделать 2 сервиса: отправлять из продюсера в консюмер по кафке и консюмером выгребать из кафки раз в минуту и в бд вставлять

хранение в бд: _banner_id, minute_timestamp, count_

| плюсы                                                                                                              | минусы             |
| ------------------------------------------------------------------------------------------------------------------ | ------------------ |
| относительная отказоустойчивость засчет отправки данных в кафку - при падении сервиса-продюсера данные не теряются | частый INSERT в бд |

---

#### мысль по реализации №3

проблема: если все 100rps будут на разные айдишники, то это будет 100 (в задании написано макс 100 айди) записей баннеров = INSERTов в бд

можно агрегировать данные по часам, в задании не описывалось необходимое временное значение актуальность данных
моменты на подумать: изучить подкапотности отправки данных чанками в кафку

хранение в бд: _banner_id, hour_timestamp, count_by_minute_object_

| плюсы                                    | минусы                                                                |
| ---------------------------------------- | --------------------------------------------------------------------- |
| относительная отказоустойчивость (кафка) | потеря в актуальности данных                                          |
| снижение нагрузки на бд                  | потеря данных в случае падения кафки если не предусмотреть репликацию |

---

#### мысль по реализации №4

если реально необходим частый INSERT в бд (и не нужен DELETE) - использовать Clickhouse, он подходит для логирования и мониторинга и аналитики больших данных, а в этом случае похожий кейс из-за стриминга данных "в реальном времени"

| плюсы                                                                                    | минусы |
| ---------------------------------------------------------------------------------------- | ------ |
| хорошо справляется с обработкой больших данных -> частый INSERT и SELECT                 |        |
| использует алгоритмы сжатия -> оптимизирует хранение большого количества данных на диске |        |

---

#### мысль по реализации №5

возможно есть еще какие-то решения для "стриминговой обработки данных"
